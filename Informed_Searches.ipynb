{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Muhid Qaiser \n",
    "\n",
    "Email : muhidqaiser02@gmail.com \n",
    "\n",
    "Linkedin : https://www.linkedin.com/in/muhid-qaiser/\n",
    "\n",
    "Github : https://github.com/Muhid-Qaiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neuron Gorge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sites.google.com/view/theneurongorge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informed Searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Distance Metrics\n",
    "- Euclidean Distance\n",
    "- Manhattan Distance\n",
    "- Minkowski Distance\n",
    "- Chebyshev Distance\n",
    "- Cosine Similarity\n",
    "- Hamming Distance\n",
    "- Best First Search (BFS)\n",
    "- A* Search\n",
    "- Practice Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristic searches are algorithms that use additional information, called heuristics, to guide the search process more efficiently towards a solution. These heuristics provide an estimate of the cost or distance to the goal, allowing the algorithm to prioritize certain paths over others. While heuristic searches don't guarantee an optimal solution, they typically find good solutions faster by focusing on the most promising options based on the given heuristics. They are commonly used in problems like pathfinding, AI planning, and optimization tasks.\n",
    "\n",
    "\n",
    "The term \"heuristic\" refers to a rule of thumb or a guiding principle\n",
    "that helps in decision-making without guaranteeing an optimal\n",
    "solution.\n",
    "\n",
    "\n",
    "In informed searches, different distance metrics are used to guide the search towards the goal by estimating the cost or closeness of a node to the target. Common metrics include **Euclidean distance**, which measures the straight-line distance between points, and **Manhattan distance**, useful in grid-based searches. **Minkowski distance** generalizes these two, offering flexibility with a parameter that adjusts sensitivity to outliers. **Chebyshev distance** measures the greatest difference in any dimension, while **Cosine similarity** evaluates angular similarity, often used in text and high-dimensional data. **Hamming distance** is applied for comparing binary strings. These metrics help prioritize nodes during search, improving efficiency by focusing on promising paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance metrics, also known as similarity measures or dissimilarity measures, quantify the similarity or dissimilarity between two data points.  They are commonly used in various fields such as machine learning, data mining, and clustering. \n",
    "\n",
    "In Informed Searches, they are used to guide the search process by providing a way to estimate the \"closeness\" or \"cost\" of reaching the goal from a given node. By incorporating distance metrics, algorithms like Best-First Search and A* can prioritize nodes that are more likely to lead to the goal, improving the efficiency of the search. The chosen distance metric helps determine which nodes to explore first, based on the heuristic that evaluates how promising a node is in achieving the goal, ultimately leading to a more optimal search strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different distance metrics are used based on data characteristics and task requirements. Here are some common uses:\n",
    "\n",
    "1. **Euclidean Distance**: Applied in geometric tasks and clustering (e.g., k-means).\n",
    "2. **Manhattan Distance**: Ideal for grid-based movement (e.g., navigation) and image processing.\n",
    "3. **Minkowski Distance**: Generalizes Euclidean and Manhattan; adjustable sensitivity to outliers.\n",
    "4. **Chebyshev Distance**: Measures similarity based on maximum difference, used in decision trees and classifiers.\n",
    "5. **Cosine Similarity**: Common in NLP for text similarity and document clustering, useful for high-dimensional data.\n",
    "6. **Hamming Distance**: Used in error detection and correction, particularly for binary strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# * Formula: √(Σ (xi - yi)²) for all dimensions\n",
    "def euclidean_distance(node, goal):\n",
    "    return math.sqrt((ord(node) - ord(goal)) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * Formula: Σ |xi - yi| for all dimensions\n",
    "def manhattan_distance(node, goal):\n",
    "    return abs(ord(node) - ord(goal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowski Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * Formula: (Σ |xi - yi|^p)^(1/p) for all dimensions\n",
    "def minkowski_distance(node, goal, p=3):\n",
    "    return (abs(ord(node) - ord(goal)) ** p) ** (1/p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chebyshev Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * Formula: max(|xi - yi|) for all dimensions\n",
    "def chebyshev_distance(node, goal):\n",
    "    return max(abs(ord(node) - ord(goal)), abs(ord(node) - ord(goal)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# * Formula: 1 - (Σ xi*yi) / (√Σ xi² * √Σ yi²) for all dimensions\n",
    "def cosine_similarity(node, goal):\n",
    "    dot_product = ord(node) * ord(goal)\n",
    "    magnitude_a = math.sqrt(ord(node) ** 2)\n",
    "    magnitude_b = math.sqrt(ord(goal) ** 2)\n",
    "    return dot_product / (magnitude_a * magnitude_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * Formula: Number of positions where xi ≠ yi\n",
    "def hamming_distance(node, goal):\n",
    "    \n",
    "    # * Ensure both nodes are of the same length\n",
    "    if len(node) != len(goal):\n",
    "        raise ValueError(\"Nodes must be of the same length for Hamming distance.\")\n",
    "    \n",
    "    return sum(el1 != el2 for el1, el2 in zip(node, goal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Input for Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 4.0\n",
      "Manhattan Distance: 4\n",
      "Minkowski Distance (p=3): 3.9999999999999996\n",
      "Chebyshev Distance: 4\n",
      "Cosine Similarity: 1.0\n",
      "Hamming Distance: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "node = \"1\"\n",
    "goal = \"5\"\n",
    "\n",
    "# * 1. Euclidean Distance\n",
    "print(\"Euclidean Distance:\", euclidean_distance(node, goal))\n",
    "\n",
    "# * 2. Manhattan Distance\n",
    "print(\"Manhattan Distance:\", manhattan_distance(node, goal))\n",
    "\n",
    "# * 3. Minkowski Distance with p=3\n",
    "print(\"Minkowski Distance (p=3):\", minkowski_distance(node, goal, p=3))\n",
    "\n",
    "# * 4. Chebyshev Distance\n",
    "print(\"Chebyshev Distance:\", chebyshev_distance(node, goal))\n",
    "\n",
    "# * 5. Cosine Similarity\n",
    "print(\"Cosine Similarity:\", cosine_similarity(node, goal))\n",
    "\n",
    "# * 6. Hamming Distance\n",
    "print(\"Hamming Distance:\", hamming_distance(node, goal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best First Search (BFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best First Search** is an informed search algorithm that selects the next node to explore based on a heuristic function, which estimates the cost to reach the goal from the current node. The algorithm prioritizes nodes that appear to be closer to the goal according to the heuristic. Unlike other search algorithms such as A*, Best First Search does not consider the actual cost incurred from the start node, focusing only on the heuristic value. It can be more efficient than uninformed searches, but may not always guarantee the shortest path, depending on the heuristic used.\n",
    "\n",
    "- Best First Search expands nodes based on the lowest heuristic value.\n",
    "\n",
    "- Best First Search is not guaranteed to be complete.\n",
    "\n",
    "- Best First Search is not optimal, as it only considers the heuristic and may not find the shortest path.\n",
    "\n",
    "- Best First Search has a time complexity that can be exponential in the worst case.\n",
    "\n",
    "- Best First Search keeps all visited nodes in memory, leading to memory overhead.\n",
    "\n",
    "- An ideal heuristic function should be as close as possible to the true cost of reaching the goal.\n",
    "\n",
    "- If h(n) = 0 for all nodes, Best First Search behaves like Greedy Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "# * Best First Search Algorithm Class\n",
    "class BFS:\n",
    "\n",
    "    # * Constructor to initialize the graph\n",
    "    def __init__(self, is_bidirectional=False):\n",
    "        self.vertices = set()\n",
    "        self.edges = {}\n",
    "        self.is_bidirectional = is_bidirectional\n",
    "    \n",
    "    # * Add an edge and vertices to the graph\n",
    "    def add_edge(self, u, v, cost):\n",
    "        self.vertices.add(u)\n",
    "        self.vertices.add(v)\n",
    "\n",
    "        # * Add the edge from u to v\n",
    "        if u not in self.edges:\n",
    "            self.edges[u] = []\n",
    "        self.edges[u].append((v, cost))\n",
    "\n",
    "        # * If the graph is bidirectional, also add the edge from v to u\n",
    "        if self.is_bidirectional:\n",
    "            if v not in self.edges:\n",
    "                self.edges[v] = []\n",
    "            self.edges[v].append((u, cost))\n",
    "\n",
    "    # * Display the graph nodes and their connections\n",
    "    def display(self):\n",
    "        print(\"Graph Nodes and their connections: \\n---------------------------------\")\n",
    "        for vertex in self.edges:\n",
    "            connections = ', '.join([f\"{neighbor} (Cost: {cost})\" for neighbor, cost in self.edges[vertex]])\n",
    "            print(f\"{vertex} -> {connections}\")\n",
    "        print()\n",
    "   \n",
    "    # * BFS Algorithm\n",
    "    def best_first_search(self, start, goal, heuristic):\n",
    "\n",
    "        # * Creating a queue and a visited set to keep track of the visited nodes\n",
    "        pq = [(0, start)]  # * Priority queue (heuristic, vertex)\n",
    "        \n",
    "        # * Set to keep track of visited nodes to avoid revisiting them during the search\n",
    "        visited = set() \n",
    "        \n",
    "        # * Dictionary to store the parent of each node. This will help in reconstructing the path later.\n",
    "        parent = {}\n",
    "        \n",
    "        # * Loop until the queue is empty\n",
    "        while pq:\n",
    "\n",
    "            # * Pop the first element from the queue\n",
    "            _, current_vertex = heapq.heappop(pq)\n",
    "            \n",
    "            # * Check if the current node is the goal\n",
    "            if current_vertex == goal:\n",
    "                return self.reconstruct_path(parent, start, goal)\n",
    "            \n",
    "            visited.add(current_vertex)\n",
    "            \n",
    "            # * Loop through the current node's connections\n",
    "            for neighbor, _ in self.edges.get(current_vertex, []):  # * Ignore the edge cost\n",
    "                \n",
    "                # * Check if the node has not been visited\n",
    "                if neighbor not in visited:\n",
    "                    priority = heuristic(neighbor, goal)  # * Use only the heuristic for priority\n",
    "                    heapq.heappush(pq, (priority, neighbor)) # * Add the node with priority to the priority queue\n",
    "                    \n",
    "                    # * Update the parent dictionary to store the current node as the parent of the neighbor.\n",
    "                    # * This helps in reconstructing the path later.\n",
    "                    parent[neighbor] = current_vertex\n",
    "        \n",
    "        print(f\"\\nCould not find the goal: {goal} with source node: {start}\")\n",
    "\n",
    "        return None  # * No path found\n",
    "    \n",
    "    # * Function to Reconstruct path from start node to goal node using optimal parents\n",
    "    def reconstruct_path(self, parent, start, goal):\n",
    "        path = [goal]\n",
    "        while path[-1] != start:\n",
    "            path.append(parent[path[-1]])\n",
    "        return path[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Nodes and their connections: \n",
      "---------------------------------\n",
      "A -> B (Cost: 4), C (Cost: 2)\n",
      "B -> C (Cost: 5), D (Cost: 10)\n",
      "C -> D (Cost: 3), E (Cost: 8)\n",
      "D -> E (Cost: 6)\n",
      "\n",
      "Path found: A -> C -> E\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Creating a graph and adding edges\n",
    "graph = BFS(is_bidirectional=False)\n",
    "graph.add_edge('A', 'B', 4)\n",
    "graph.add_edge('A', 'C', 2)\n",
    "graph.add_edge('B', 'C', 5)\n",
    "graph.add_edge('B', 'D', 10)\n",
    "graph.add_edge('C', 'D', 3)\n",
    "graph.add_edge('C', 'E', 8)\n",
    "graph.add_edge('D', 'E', 6)\n",
    "\n",
    "start_vertex = 'A'\n",
    "goal_vertex = 'E'\n",
    "\n",
    "# * Display Graph\n",
    "graph.display()\n",
    "\n",
    "# * Define a heuristic function (Manhattan distance)\n",
    "def heuristic(node, goal):\n",
    "    return manhattan_distance(node, goal)\n",
    "\n",
    "# * Apply BFS Algorithm on the graph for the given Start and Goal Node\n",
    "path = graph.best_first_search(start_vertex, goal_vertex, heuristic)\n",
    "if path:\n",
    "    print(\"Path found:\", ' -> '.join(path))\n",
    "else:\n",
    "    print(\"No path found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A* search is an informed search algorithm that finds the shortest path in a weighted graph by combining the actual cost to reach a node (**g-value**) and the estimated cost to the goal (**h-value**). It selects nodes based on the lowest **f(n) = g(n) + h(n)**. A* guarantees an optimal solution if the heuristic is admissible. It's commonly used in pathfinding applications like video games and robotics.\n",
    "\n",
    "- A* Search expands the nodes as f-value increases.\n",
    "\n",
    "- A* Search is complete.\n",
    "\n",
    "- A* Search is optimal, if heuristic is admissible.\n",
    "\n",
    "- A* Search has exponential time complexity.\n",
    "\n",
    "- A* Search keeps all nodes in the memory.\n",
    "\n",
    "- An ideal heuristic function is close to the cost function.\n",
    "\n",
    "- If h(n)=0, the search will be the Uniform Cost Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "# * A* Search Algorithm Class\n",
    "class A_star:\n",
    "\n",
    "    # * Constructor to initialize the graph\n",
    "    def __init__(self, is_bidirectional=False):\n",
    "        self.vertices = set()\n",
    "        self.edges = {}\n",
    "        self.is_bidirectional = is_bidirectional\n",
    "    \n",
    "    # * Add an edge and vertices to the graph\n",
    "    def add_edge(self, u, v, cost):\n",
    "        self.vertices.add(u)\n",
    "        self.vertices.add(v)\n",
    "\n",
    "        # * Add the edge from u to v\n",
    "        if u not in self.edges:\n",
    "            self.edges[u] = []\n",
    "        self.edges[u].append((v, cost))\n",
    "\n",
    "        # * If the graph is bidirectional, also add the edge from v to u\n",
    "        if self.is_bidirectional:\n",
    "            if v not in self.edges:\n",
    "                self.edges[v] = []\n",
    "            self.edges[v].append((u, cost))\n",
    "\n",
    "    # * Display the graph nodes and their connections\n",
    "    def display(self):\n",
    "        print(\"Graph Nodes and their connections: \\n---------------------------------\")\n",
    "        for vertex in self.edges:\n",
    "            connections = ', '.join([f\"{neighbor} (Cost: {cost})\" for neighbor, cost in self.edges[vertex]])\n",
    "            print(f\"{vertex} -> {connections}\")\n",
    "        print()\n",
    "   \n",
    "    # * A* Search Algorithm\n",
    "    def a_star_search(self, start, goal, heuristic):\n",
    "        \n",
    "        # * Creating a queue and a visited set to keep track of the visited nodes\n",
    "        pq = [(0, start)]  # * Priority queue (cost, vertex)\n",
    "        \n",
    "        # * Set to keep track of visited nodes to avoid revisiting them during the search\n",
    "        visited = set() \n",
    "\n",
    "        # * Dictionary to store the cost to reach each vertex from the start node.\n",
    "        # * Initially, set all vertex costs to infinity (i.e., unreachable), except for the start node.\n",
    "        cost_so_far = {vertex: float('inf') for vertex in self.vertices}\n",
    "        cost_so_far[start] = 0\n",
    "        \n",
    "        # * Dictionary to store the parent of each node. This will help in reconstructing the path later.\n",
    "        parent = {}\n",
    "        \n",
    "        # * Loop until the queue is empty\n",
    "        while pq:\n",
    "\n",
    "            # * Pop the first element from the queue\n",
    "            current_cost, current_vertex = heapq.heappop(pq)\n",
    "            \n",
    "            # * Check if the current node is the goal\n",
    "            if current_vertex == goal:\n",
    "                return self.reconstruct_path(parent, start, goal)\n",
    "            \n",
    "            visited.add(current_vertex)\n",
    "            \n",
    "            # * Loop through the current node's connections\n",
    "            for neighbor, edge_cost in self.edges.get(current_vertex, []):\n",
    "\n",
    "                # * Check if the node has not been visited\n",
    "                if neighbor not in visited:\n",
    "\n",
    "                    # * Calculate new cost as sum of cost to reach current node + cost to reach the neighboring node\n",
    "                    new_cost = cost_so_far[current_vertex] + edge_cost\n",
    "\n",
    "                    # * Check if the newly calculated cost to reach the neighboring node is lower\n",
    "                    # * than the previously recorded cost. If so, update the cost and proceed.\n",
    "                    if new_cost < cost_so_far[neighbor]:\n",
    "\n",
    "                        # * Update the cost for this node\n",
    "                        cost_so_far[neighbor] = new_cost\n",
    "\n",
    "                        # * Calculate the priority for this node as the sum of the actual cost (new_cost)\n",
    "                        # * and the heuristic value (estimated cost to the goal).\n",
    "                        priority = new_cost + heuristic(neighbor, goal)\n",
    "\n",
    "                        # * Push the neighbor into the priority queue with the new priority (f(n)).\n",
    "                        # * The queue always keeps the node with the lowest f(n) at the front.\n",
    "                        heapq.heappush(pq, (priority, neighbor))\n",
    "\n",
    "                        # * Update the parent dictionary to store the current node as the parent of the neighbor.\n",
    "                        # * This helps in reconstructing the path later.\n",
    "                        parent[neighbor] = current_vertex\n",
    "        \n",
    "        print(f\"\\nCould not find the goal: {goal} with source node: {start}\")\n",
    "\n",
    "        return None  # * No path found\n",
    "    \n",
    "    # * Function to Reconstruct path from start node to goal node using optimal parents\n",
    "    def reconstruct_path(self, parent, start, goal):\n",
    "        path = [goal]\n",
    "        while path[-1] != start:\n",
    "            path.append(parent[path[-1]])\n",
    "        return path[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Nodes and their connections: \n",
      "---------------------------------\n",
      "A -> B (Cost: 4), C (Cost: 2)\n",
      "B -> C (Cost: 5), D (Cost: 10)\n",
      "C -> D (Cost: 3), E (Cost: 8)\n",
      "D -> E (Cost: 6)\n",
      "\n",
      "Path found: A -> C -> E\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Creating a graph and adding edges\n",
    "graph = A_star(is_bidirectional=False)\n",
    "graph.add_edge('A', 'B', 4)\n",
    "graph.add_edge('A', 'C', 2)\n",
    "graph.add_edge('B', 'C', 5)\n",
    "graph.add_edge('B', 'D', 10)\n",
    "graph.add_edge('C', 'D', 3)\n",
    "graph.add_edge('C', 'E', 8)\n",
    "graph.add_edge('D', 'E', 6)\n",
    "\n",
    "start_vertex = 'A'\n",
    "goal_vertex = 'E'\n",
    "\n",
    "# * Display Graph\n",
    "graph.display()\n",
    "\n",
    "# * Define a heuristic function (Manhattan distance)\n",
    "def heuristic(node, goal):\n",
    "    return manhattan_distance(node, goal)\n",
    "\n",
    "# * Apply A* Algorithm on the graph for the given Start and Goal Node\n",
    "path = graph.a_star_search(start_vertex, goal_vertex, heuristic)\n",
    "if path:\n",
    "    print(\"Path found:\", ' -> '.join(path))\n",
    "else:\n",
    "    print(\"No path found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 : Create a Robot Navigation System using Best First Search and A* Search\n",
    "\n",
    "Design and implement a robot navigation system where starting state and the goal state have been\n",
    "given which are basically the coordinates of the randomly generated grid of size 15x15 . For example,\n",
    "the start state has the coordinates is (1,2) and the goal state has the coordinates (15,14).\n",
    "Consider the following assumptions during the implementation of the robot navigation system:\n",
    "\n",
    "- The robot can only move,\n",
    "    - Up one cell with step cost 2,\n",
    "    - Right one cell with cost 2,\n",
    "    - Diagonally Up towards the right with cost 3.\n",
    "- The robot cannot move downward one cell.\n",
    "- The obstacles are randomly placed in the grid upon grid generation, and the robot cannot be in those cells.\n",
    "- Your task is to implement using both Best First Search and A* Search\n",
    "\n",
    "Your designed system should output the followings:\n",
    "- The complete path as well as the traversal if the goal is reachable otherwise mention failure with\n",
    "some solid reasons.\n",
    "- The sequence of actions performed to reach the goal.\n",
    "- The total cost of the path.\n",
    "- A grid that shows the path followed. You do not need graphics for this output.\n",
    "\n",
    "Hints\n",
    "- The grid can be made textually using 1 for obstacles, 0 for empty cells (where the robot can\n",
    "move) and ‘*’ for path followed.\n",
    "- For a heuristic-based search algorithm, you can use the Manhattan distance as a heuristic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 : Word Ladder Problem using Best First Search\n",
    "Problem:\n",
    "You are given two words, start and end, and a dictionary of valid words. The goal is to find the shortest transformation sequence from the start word to the end word, where each word differs by only one letter from the previous word, and every intermediate word must also be a valid word in the dictionary. Use the Best First Search algorithm to find the shortest transformation sequence.\n",
    "\n",
    "The heuristic function to use is the number of letters that differ between the current word and the end word.\n",
    "Example:\n",
    "\n",
    "Start Word: \"hit\"\n",
    "End Word: \"cog\"\n",
    "Dictionary: [\"hot\", \"dot\", \"dog\", \"lot\", \"log\", \"cog\"]\n",
    "\n",
    "Find the shortest transformation sequence from \"hit\" to \"cog\" using Best First Search and return the sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 : Solve the 8 Puzzle Problem using A Search*\n",
    "Problem:\n",
    "You are given a 3x3 grid with tiles numbered 1 to 8 and a blank space (represented as 0). The goal is to move the tiles to reach a specified goal configuration by sliding the tiles into the blank space. Use the A search algorithm* to find the shortest sequence of moves that will solve the puzzle.\n",
    "\n",
    "The heuristic function you should use is Manhattan Distance, which is the sum of the absolute differences in the x and y coordinates between the current tile position and the goal tile position.\n",
    "The grid starts with the start_state configuration, and you need to find the minimum number of moves to reach the goal_state configuration.\n",
    "\n",
    "Use the Start and Goal states provided below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! Do not change the Grids below\n",
    "\n",
    "# * Start State Grid\n",
    "start_state = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 0]\n",
    "]\n",
    "\n",
    "# * Goal State Grid\n",
    "goal_state = [\n",
    "    [1, 2, 3],\n",
    "    [8, 0, 4],\n",
    "    [7, 6, 5]\n",
    "]\n",
    "\n",
    "# * Write Your Implementation Below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy Coding :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
